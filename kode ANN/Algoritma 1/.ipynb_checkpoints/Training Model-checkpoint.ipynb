{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ7V6g2BxDAT"
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryLJLUNmxc_Z"
   },
   "source": [
    "Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9hOu6axEx4nq",
    "outputId": "e60cdb6f-84fa-44b0-b228-23cd2791a6f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNAfBz4Qx5fy"
   },
   "source": [
    "import data dari csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "otFjft9xxcdJ"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('fix2.csv')\n",
    "\n",
    "x = dataset.iloc[:, 1:5].values\n",
    "y0 = dataset.iloc[:, 8].values\n",
    "y1 = dataset.iloc[:, 9].values\n",
    "y2 = dataset.iloc[:, 10].values\n",
    "y3 = dataset.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:6].values\n",
    "Y0 = dataset.iloc[:, 12].values\n",
    "Y1 = dataset.iloc[:, 13].values\n",
    "Y2 = dataset.iloc[:, 14].values\n",
    "Y3 = dataset.iloc[:, 15].values\n",
    "Y4 = dataset.iloc[:, 16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 3.000e+00, 2.700e+01, 1.880e+02],\n",
       "       [1.000e+00, 3.000e+00, 2.690e+01, 7.900e+01],\n",
       "       [1.000e+00, 3.000e+00, 2.700e+01, 1.100e+01],\n",
       "       ...,\n",
       "       [1.000e+00, 0.000e+00, 2.530e+01, 7.930e+02],\n",
       "       [1.000e+00, 0.000e+00, 2.540e+01, 1.052e+03],\n",
       "       [1.000e+00, 0.000e+00, 2.530e+01, 9.770e+02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpsM9N9XzQj6"
   },
   "source": [
    "bikin dataset train dan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ACudBgU9zPWz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y0_train, y0_test = train_test_split(x,y0, test_size = 0.2, random_state = 0)\n",
    "x_train, x_test, y1_train, y1_test = train_test_split(x,y1, test_size = 0.2, random_state = 0)\n",
    "x_train, x_test, y2_train, y2_test = train_test_split(x,y2, test_size = 0.2, random_state = 0)\n",
    "x_train, x_test, y3_train, y3_test = train_test_split(x,y3, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y0_train, Y0_test = train_test_split(X,Y0, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test, Y1_train, Y1_test = train_test_split(X,Y1, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test, Y2_train, Y2_test = train_test_split(X,Y2, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test, Y3_train, Y3_test = train_test_split(X,Y3, test_size = 0.2, random_state = 0)\n",
    "X_train, X_test, Y4_train, Y4_test = train_test_split(X,Y4, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZRuwbUEz7Mh"
   },
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IACSwotSzb3f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = StandardScaler()\n",
    "X_train = SC.fit_transform(X_train)\n",
    "X_test = SC.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbVabnVt0l6e"
   },
   "source": [
    "**Machine Learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv8w-77N0qg3"
   },
   "source": [
    "**Inisiasi ML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXPUuYYT3JgP"
   },
   "source": [
    "inisiasi dengan sequensial class (tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GSdFXPc10uFN"
   },
   "outputs": [],
   "source": [
    "ann0 = tf.keras.models.Sequential()\n",
    "ann1 = tf.keras.models.Sequential()\n",
    "ann2 = tf.keras.models.Sequential()\n",
    "ann3 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN0 = tf.keras.models.Sequential()\n",
    "ANN1 = tf.keras.models.Sequential()\n",
    "ANN2 = tf.keras.models.Sequential()\n",
    "ANN3 = tf.keras.models.Sequential()\n",
    "ANN4 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upctF73l3UXP"
   },
   "source": [
    "add 32 neuron dengan relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2cjgPcVW3HpN"
   },
   "outputs": [],
   "source": [
    "ann0.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ann1.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ann2.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ann3.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN0.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ANN1.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ANN2.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ANN3.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "ANN4.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR0uUZzR3iu0"
   },
   "source": [
    "add 16 neuron dengan relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uy-3BnVW3iUA"
   },
   "outputs": [],
   "source": [
    "ann0.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ann1.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ann2.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ann3.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uy-3BnVW3iUA"
   },
   "outputs": [],
   "source": [
    "ANN0.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ANN1.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ANN2.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ANN3.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "ANN4.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQNHbrM534gh"
   },
   "source": [
    "add output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jUnujAZo35DV"
   },
   "outputs": [],
   "source": [
    "ann0.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ann1.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ann2.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ann3.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN0.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ANN1.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ANN2.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ANN3.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "ANN4.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp7C6_YF4UTB"
   },
   "source": [
    "**Train ML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmYBwjxG4f-H"
   },
   "source": [
    "Compile pakai adam optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QL_RI-qK4Y09"
   },
   "outputs": [],
   "source": [
    "ann0.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QL_RI-qK4Y09"
   },
   "outputs": [],
   "source": [
    "ANN0.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ANN1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ANN2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ANN3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ANN4.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKCoqpnu43K1"
   },
   "source": [
    "training dengan 100 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_U8VKh15DJF",
    "outputId": "0865142b-7e9b-4cfb-92a1-f4b92635cfa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.7792 - accuracy: 0.3780\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.6547 - accuracy: 0.6524\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.5599 - accuracy: 0.7724\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.4856 - accuracy: 0.8008\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.4281 - accuracy: 0.8354\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.3814 - accuracy: 0.8659\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.3472 - accuracy: 0.8679\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.3211 - accuracy: 0.8720\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.3019 - accuracy: 0.8821\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2854 - accuracy: 0.8862\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 225us/sample - loss: 0.2733 - accuracy: 0.8821\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.2621 - accuracy: 0.8963\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.2511 - accuracy: 0.9045\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.2420 - accuracy: 0.9065\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2332 - accuracy: 0.9106\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.2252 - accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.2179 - accuracy: 0.9126\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.2112 - accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.2051 - accuracy: 0.9146\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2002 - accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1955 - accuracy: 0.9228\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1927 - accuracy: 0.9228\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1864 - accuracy: 0.9309\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1825 - accuracy: 0.9309\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1794 - accuracy: 0.9309\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1776 - accuracy: 0.9309\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1713 - accuracy: 0.9350\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1679 - accuracy: 0.9411\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1653 - accuracy: 0.9390\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1614 - accuracy: 0.9431\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.1579 - accuracy: 0.9390\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1558 - accuracy: 0.9390\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1517 - accuracy: 0.9492\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1506 - accuracy: 0.9451\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1473 - accuracy: 0.9451\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1449 - accuracy: 0.9451\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1404 - accuracy: 0.9533\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1375 - accuracy: 0.9451\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1346 - accuracy: 0.9472\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1308 - accuracy: 0.9512\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1295 - accuracy: 0.9533\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1263 - accuracy: 0.9533\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1246 - accuracy: 0.9512\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1209 - accuracy: 0.9593\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1188 - accuracy: 0.9593\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1167 - accuracy: 0.9553\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 60us/sample - loss: 0.1155 - accuracy: 0.9573\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1127 - accuracy: 0.9553\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1099 - accuracy: 0.9593\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1093 - accuracy: 0.9573\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 50us/sample - loss: 0.1082 - accuracy: 0.9634\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.1066 - accuracy: 0.9614\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1027 - accuracy: 0.9573\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1020 - accuracy: 0.9573\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1001 - accuracy: 0.9553\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0988 - accuracy: 0.9593\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0976 - accuracy: 0.9614\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0964 - accuracy: 0.9553\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0945 - accuracy: 0.9573\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0934 - accuracy: 0.9573\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0925 - accuracy: 0.9614\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0916 - accuracy: 0.9573\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0901 - accuracy: 0.9573\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0901 - accuracy: 0.9715\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0877 - accuracy: 0.9593\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0861 - accuracy: 0.9634\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0867 - accuracy: 0.9614\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0839 - accuracy: 0.9614\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0869 - accuracy: 0.9817\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0830 - accuracy: 0.9593\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0821 - accuracy: 0.9654\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0803 - accuracy: 0.9634\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0800 - accuracy: 0.9756\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0795 - accuracy: 0.9614\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0784 - accuracy: 0.9614\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0773 - accuracy: 0.9715\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0783 - accuracy: 0.9634\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0768 - accuracy: 0.9797\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0764 - accuracy: 0.9614\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0751 - accuracy: 0.9797\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0765 - accuracy: 0.9614\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0750 - accuracy: 0.9756\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0714 - accuracy: 0.9736\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0711 - accuracy: 0.9695\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0701 - accuracy: 0.9715\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0715 - accuracy: 0.9776\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0691 - accuracy: 0.9776\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0682 - accuracy: 0.9797\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0679 - accuracy: 0.9776\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0679 - accuracy: 0.9776\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0663 - accuracy: 0.9817\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0673 - accuracy: 0.9837\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0664 - accuracy: 0.9695\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0666 - accuracy: 0.9858\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0677 - accuracy: 0.9675\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0654 - accuracy: 0.9878\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0644 - accuracy: 0.9837\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0633 - accuracy: 0.9756\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0631 - accuracy: 0.9898\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0647 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afad3fe408>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann0.fit(x_train, y0_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.4952 - accuracy: 0.8557\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.4181 - accuracy: 0.8557\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.3653 - accuracy: 0.8557\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3301 - accuracy: 0.8557\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.3046 - accuracy: 0.8557\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.2856 - accuracy: 0.8557\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2700 - accuracy: 0.8557\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 77us/sample - loss: 0.2576 - accuracy: 0.8557\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.2468 - accuracy: 0.8557\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.2375 - accuracy: 0.8557\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.2273 - accuracy: 0.8557\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.2179 - accuracy: 0.8557\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.2097 - accuracy: 0.8963\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2030 - accuracy: 0.9085\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 46us/sample - loss: 0.1966 - accuracy: 0.9045\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1907 - accuracy: 0.9126\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1844 - accuracy: 0.9126\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1788 - accuracy: 0.9187\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1736 - accuracy: 0.9146\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.93 - 0s 47us/sample - loss: 0.1688 - accuracy: 0.9207\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1645 - accuracy: 0.9228\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1606 - accuracy: 0.9289\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1570 - accuracy: 0.9370\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1539 - accuracy: 0.9370\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1496 - accuracy: 0.9451\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1469 - accuracy: 0.9472\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1430 - accuracy: 0.9533\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1419 - accuracy: 0.9472\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1411 - accuracy: 0.9451\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1358 - accuracy: 0.9573\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1328 - accuracy: 0.9492\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1297 - accuracy: 0.9533\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1283 - accuracy: 0.9533\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1246 - accuracy: 0.9553\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1241 - accuracy: 0.9614\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1200 - accuracy: 0.9553\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1194 - accuracy: 0.9553\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1170 - accuracy: 0.9573\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.1150 - accuracy: 0.9593\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1143 - accuracy: 0.9634\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1115 - accuracy: 0.9593\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.1100 - accuracy: 0.9573\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.1088 - accuracy: 0.9593\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1066 - accuracy: 0.9593\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1042 - accuracy: 0.9593\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1029 - accuracy: 0.9614\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1008 - accuracy: 0.9593\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0992 - accuracy: 0.9614\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0966 - accuracy: 0.9634\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0952 - accuracy: 0.9634\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0955 - accuracy: 0.9654\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0940 - accuracy: 0.9654\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0926 - accuracy: 0.9675\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0909 - accuracy: 0.9593\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0893 - accuracy: 0.9675\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0882 - accuracy: 0.9654\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0856 - accuracy: 0.9654\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0856 - accuracy: 0.9675\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0852 - accuracy: 0.9675\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0832 - accuracy: 0.9695\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0836 - accuracy: 0.9634\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 50us/sample - loss: 0.0822 - accuracy: 0.9675\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0799 - accuracy: 0.9675\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0802 - accuracy: 0.9654\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0799 - accuracy: 0.9675\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0773 - accuracy: 0.9695\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0759 - accuracy: 0.9675\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0783 - accuracy: 0.9715\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0758 - accuracy: 0.9715\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0769 - accuracy: 0.9715\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.0757 - accuracy: 0.9695\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0734 - accuracy: 0.9715\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 58us/sample - loss: 0.0720 - accuracy: 0.9695\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0734 - accuracy: 0.9695\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0744 - accuracy: 0.9715\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0753 - accuracy: 0.9736\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.0705 - accuracy: 0.9715\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0694 - accuracy: 0.9715\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0691 - accuracy: 0.9695\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0676 - accuracy: 0.9715\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0686 - accuracy: 0.9736\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0700 - accuracy: 0.9756\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0668 - accuracy: 0.9736\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0661 - accuracy: 0.9695\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0658 - accuracy: 0.9715\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0650 - accuracy: 0.9715\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0651 - accuracy: 0.9736\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0644 - accuracy: 0.9736\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0648 - accuracy: 0.9756\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0657 - accuracy: 0.9736\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0633 - accuracy: 0.9756\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0622 - accuracy: 0.9715\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0629 - accuracy: 0.9736\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0610 - accuracy: 0.9736\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0613 - accuracy: 0.9736\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0612 - accuracy: 0.9736\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0603 - accuracy: 0.9736\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0606 - accuracy: 0.9736\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0598 - accuracy: 0.9715\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0601 - accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afaebd09c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann1.fit(x_train, y1_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.5649 - accuracy: 0.9329\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.4322 - accuracy: 0.9837\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3163 - accuracy: 0.9837\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.2223 - accuracy: 0.9837\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1564 - accuracy: 0.9837\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1138 - accuracy: 0.9837\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0889 - accuracy: 0.9837\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.0740 - accuracy: 0.9837\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0622 - accuracy: 0.9837\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.0544 - accuracy: 0.9837\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0481 - accuracy: 0.9837\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0428 - accuracy: 0.9837\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0386 - accuracy: 0.9837\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0349 - accuracy: 0.9837\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0318 - accuracy: 0.9837\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0289 - accuracy: 0.9837\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0268 - accuracy: 0.9837\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0249 - accuracy: 0.9837\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0230 - accuracy: 0.9837\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0216 - accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.0203 - accuracy: 0.9837\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0191 - accuracy: 0.9837\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0181 - accuracy: 0.9837\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0170 - accuracy: 0.9837\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0162 - accuracy: 0.9837\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0153 - accuracy: 0.9837\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0145 - accuracy: 0.9837\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0139 - accuracy: 0.9898\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0132 - accuracy: 0.9959\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 69us/sample - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 44us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 46us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 9.9180e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 9.5646e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 9.2283e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 8.8416e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 8.5912e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 8.3203e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 7.9864e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 7.6819e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 7.4447e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 7.1859e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 6.9659e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 6.7595e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 6.5743e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 6.3601e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 6.2099e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 6.0722e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 5.8336e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 5.6302e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 5.5229e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 5.3236e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 5.1677e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 5.0099e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 4.8535e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 4.7175e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 4.6072e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afaf005388>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann2.fit(x_train, y2_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.6868 - accuracy: 0.6016\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.5551 - accuracy: 0.8720\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.4612 - accuracy: 0.9370\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.3809 - accuracy: 0.9370\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 69us/sample - loss: 0.3158 - accuracy: 0.9370\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.2636 - accuracy: 0.9370\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2247 - accuracy: 0.9370\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1980 - accuracy: 0.9370\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1800 - accuracy: 0.9370\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1671 - accuracy: 0.9370\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1566 - accuracy: 0.9370\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 71us/sample - loss: 0.1472 - accuracy: 0.9370\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.1389 - accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 77us/sample - loss: 0.1313 - accuracy: 0.9370\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1248 - accuracy: 0.9370\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1186 - accuracy: 0.9370\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1128 - accuracy: 0.9370\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1074 - accuracy: 0.9390\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1027 - accuracy: 0.9492\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0983 - accuracy: 0.9472\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0940 - accuracy: 0.9512\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0908 - accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0877 - accuracy: 0.9634\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0854 - accuracy: 0.9675\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0828 - accuracy: 0.9675\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0806 - accuracy: 0.9675\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0786 - accuracy: 0.9675\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0765 - accuracy: 0.9675\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0744 - accuracy: 0.9675\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0729 - accuracy: 0.9675\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0712 - accuracy: 0.9695\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0695 - accuracy: 0.9715\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0679 - accuracy: 0.9695\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0667 - accuracy: 0.9675\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0654 - accuracy: 0.9695\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0649 - accuracy: 0.9715\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0625 - accuracy: 0.9736\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0616 - accuracy: 0.9715\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0610 - accuracy: 0.9736\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0592 - accuracy: 0.9756\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0593 - accuracy: 0.9715\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0568 - accuracy: 0.9776\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0564 - accuracy: 0.9797\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 52us/sample - loss: 0.0553 - accuracy: 0.9797\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0542 - accuracy: 0.9797\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0531 - accuracy: 0.9776\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0524 - accuracy: 0.9776\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0520 - accuracy: 0.9776\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0505 - accuracy: 0.9817\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0502 - accuracy: 0.9797\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0499 - accuracy: 0.9776\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0520 - accuracy: 0.9797\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0495 - accuracy: 0.9817\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0470 - accuracy: 0.9858\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0466 - accuracy: 0.9837\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 54us/sample - loss: 0.0460 - accuracy: 0.9817\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0450 - accuracy: 0.9817\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0445 - accuracy: 0.9858\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0440 - accuracy: 0.9837\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 58us/sample - loss: 0.0438 - accuracy: 0.9858\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0425 - accuracy: 0.9858\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0423 - accuracy: 0.9878\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0414 - accuracy: 0.9878\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0420 - accuracy: 0.9837\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0409 - accuracy: 0.9878\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0420 - accuracy: 0.9837\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0391 - accuracy: 0.9858\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0402 - accuracy: 0.9878\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0384 - accuracy: 0.9878\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0378 - accuracy: 0.9858\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0372 - accuracy: 0.9858\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0368 - accuracy: 0.9898\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0366 - accuracy: 0.9898\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0361 - accuracy: 0.9837\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0361 - accuracy: 0.9898\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0374 - accuracy: 0.9858\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0343 - accuracy: 0.9858\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0340 - accuracy: 0.9898\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0337 - accuracy: 0.9878\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0335 - accuracy: 0.9878\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0334 - accuracy: 0.9878\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0324 - accuracy: 0.9878\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0329 - accuracy: 0.9858\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0317 - accuracy: 0.9898\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0322 - accuracy: 0.9878\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0317 - accuracy: 0.9878\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 1.00 - 0s 55us/sample - loss: 0.0307 - accuracy: 0.9898\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0308 - accuracy: 0.9878\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0308 - accuracy: 0.9898\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0298 - accuracy: 0.9898\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0290 - accuracy: 0.9919\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0304 - accuracy: 0.9858\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0286 - accuracy: 0.9919\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0298 - accuracy: 0.9898\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0277 - accuracy: 0.9919\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0280 - accuracy: 0.9919\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0272 - accuracy: 0.9919\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0272 - accuracy: 0.9919\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0273 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afb03e0288>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann3.fit(x_train, y3_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.8159 - accuracy: 0.2480\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.6203 - accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.4858 - accuracy: 0.9065\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.3870 - accuracy: 0.9350\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.3131 - accuracy: 0.9350\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2592 - accuracy: 0.9350\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.2232 - accuracy: 0.9350\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1991 - accuracy: 0.9350\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1828 - accuracy: 0.9350\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.1708 - accuracy: 0.9350\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1618 - accuracy: 0.9350\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1543 - accuracy: 0.9350\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1481 - accuracy: 0.9350\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1425 - accuracy: 0.9350\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1377 - accuracy: 0.9350\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1331 - accuracy: 0.9350\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1285 - accuracy: 0.9350\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1241 - accuracy: 0.9350\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1201 - accuracy: 0.9350\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1163 - accuracy: 0.9350\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.93 - 0s 57us/sample - loss: 0.1124 - accuracy: 0.9350\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1085 - accuracy: 0.9350\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.1046 - accuracy: 0.9350\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1008 - accuracy: 0.9350\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0971 - accuracy: 0.9350\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.0937 - accuracy: 0.9390\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.0901 - accuracy: 0.9492\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 64us/sample - loss: 0.0863 - accuracy: 0.9533\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0832 - accuracy: 0.9654\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0796 - accuracy: 0.9756\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0766 - accuracy: 0.9797\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0734 - accuracy: 0.9837\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0707 - accuracy: 0.9817\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.0676 - accuracy: 0.9837\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.0647 - accuracy: 0.9878\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0621 - accuracy: 0.9858\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0596 - accuracy: 0.9878\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0571 - accuracy: 0.9878\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0547 - accuracy: 0.9878\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0522 - accuracy: 0.9898\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0501 - accuracy: 0.9898\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0482 - accuracy: 0.9898\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0462 - accuracy: 0.9898\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0444 - accuracy: 0.9898\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0427 - accuracy: 0.9898\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0411 - accuracy: 0.9898\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0394 - accuracy: 0.9919\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0378 - accuracy: 0.9919\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0364 - accuracy: 0.9919\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0350 - accuracy: 0.9919\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0337 - accuracy: 0.9919\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0325 - accuracy: 0.9919\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0316 - accuracy: 0.9919\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0303 - accuracy: 0.9919\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0293 - accuracy: 0.9919\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0285 - accuracy: 0.9919\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0274 - accuracy: 0.9919\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0260 - accuracy: 0.9919\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0251 - accuracy: 0.9939\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0244 - accuracy: 0.9939\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0236 - accuracy: 0.9939\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0229 - accuracy: 0.9939\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0222 - accuracy: 0.9939\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0215 - accuracy: 0.9939\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0211 - accuracy: 0.9939\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0205 - accuracy: 0.9939\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0199 - accuracy: 0.9939\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0194 - accuracy: 0.9959\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0183 - accuracy: 0.9939\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0180 - accuracy: 0.9939\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0175 - accuracy: 0.9939\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0169 - accuracy: 0.9959\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0168 - accuracy: 0.9959\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0160 - accuracy: 0.9959\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0157 - accuracy: 0.9959\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0153 - accuracy: 0.9959\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0149 - accuracy: 0.9959\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0145 - accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0142 - accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0138 - accuracy: 0.9959\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0135 - accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0131 - accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0129 - accuracy: 0.9980\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 50us/sample - loss: 0.0125 - accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0124 - accuracy: 0.9980\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0123 - accuracy: 0.9980\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0121 - accuracy: 0.9980\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0117 - accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0111 - accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0108 - accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0106 - accuracy: 0.9980\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0099 - accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0092 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afb08e3f88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN0.fit(X_train, Y0_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.7083 - accuracy: 0.5488\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.6079 - accuracy: 0.7276\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.5445 - accuracy: 0.7622\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.5035 - accuracy: 0.7825\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.4773 - accuracy: 0.7927\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.4574 - accuracy: 0.8008\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.4420 - accuracy: 0.8150\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.4283 - accuracy: 0.8191\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.4169 - accuracy: 0.8130\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.4047 - accuracy: 0.8110\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.3934 - accuracy: 0.8171\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3821 - accuracy: 0.8252\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3706 - accuracy: 0.8293\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.3595 - accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3490 - accuracy: 0.8394\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.3392 - accuracy: 0.8476\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.3291 - accuracy: 0.8557\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.3184 - accuracy: 0.8638\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.3084 - accuracy: 0.8659\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2988 - accuracy: 0.8699\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.2892 - accuracy: 0.8720\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.2799 - accuracy: 0.8801\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.2704 - accuracy: 0.8801\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2611 - accuracy: 0.8821\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.2519 - accuracy: 0.8882\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2427 - accuracy: 0.8923\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2348 - accuracy: 0.9004\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.2247 - accuracy: 0.9065\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 52us/sample - loss: 0.2167 - accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.2086 - accuracy: 0.9268\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1995 - accuracy: 0.9329\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1910 - accuracy: 0.9451\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1825 - accuracy: 0.9492\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1754 - accuracy: 0.9512\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1691 - accuracy: 0.9533\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 64us/sample - loss: 0.1619 - accuracy: 0.9573\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1556 - accuracy: 0.9553\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1503 - accuracy: 0.9533\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1453 - accuracy: 0.9573\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1402 - accuracy: 0.9614\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1349 - accuracy: 0.9593\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1305 - accuracy: 0.9614\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1261 - accuracy: 0.9675\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1217 - accuracy: 0.9654\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.96 - 0s 49us/sample - loss: 0.1172 - accuracy: 0.9695\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1135 - accuracy: 0.9695\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1099 - accuracy: 0.9736\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 50us/sample - loss: 0.1072 - accuracy: 0.9736\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1028 - accuracy: 0.9756\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1000 - accuracy: 0.9756\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0972 - accuracy: 0.9756\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0948 - accuracy: 0.9736\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0920 - accuracy: 0.9817\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0891 - accuracy: 0.9797\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0869 - accuracy: 0.9756\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 46us/sample - loss: 0.0845 - accuracy: 0.9837\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0817 - accuracy: 0.9817\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0799 - accuracy: 0.9817\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0775 - accuracy: 0.9858\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0761 - accuracy: 0.9858\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0738 - accuracy: 0.9858\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0720 - accuracy: 0.9817\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0706 - accuracy: 0.9858\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0680 - accuracy: 0.9878\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 83us/sample - loss: 0.0666 - accuracy: 0.9878\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.0658 - accuracy: 0.9858\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0639 - accuracy: 0.9858\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0618 - accuracy: 0.9878\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0611 - accuracy: 0.9878\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0590 - accuracy: 0.9878\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0576 - accuracy: 0.9878\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0566 - accuracy: 0.9878\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0552 - accuracy: 0.9898\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0543 - accuracy: 0.9878\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0527 - accuracy: 0.9898\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0528 - accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0507 - accuracy: 0.9898\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0495 - accuracy: 0.9919\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0487 - accuracy: 0.9919\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0474 - accuracy: 0.9919\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0462 - accuracy: 0.9939\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0454 - accuracy: 0.9939\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0445 - accuracy: 0.9919\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0444 - accuracy: 0.9939\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0438 - accuracy: 0.9939\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0421 - accuracy: 0.9959\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0415 - accuracy: 0.9939\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0404 - accuracy: 0.9939\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0394 - accuracy: 0.9959\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0387 - accuracy: 0.9959\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0382 - accuracy: 0.9959\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0374 - accuracy: 0.9959\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0365 - accuracy: 0.9959\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0364 - accuracy: 0.9959\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0360 - accuracy: 0.9959\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0350 - accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0345 - accuracy: 0.9959\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0332 - accuracy: 0.9959\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.0331 - accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0318 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afb1cb2e48>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN1.fit(X_train, Y1_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.6509 - accuracy: 0.6443\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.5032 - accuracy: 0.9045\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3965 - accuracy: 0.9350\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.3164 - accuracy: 0.9289\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2601 - accuracy: 0.9289\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2252 - accuracy: 0.9289\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.2006 - accuracy: 0.9289\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1844 - accuracy: 0.9289\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1718 - accuracy: 0.9289\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.1609 - accuracy: 0.9289\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1517 - accuracy: 0.9289\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 69us/sample - loss: 0.1427 - accuracy: 0.9289\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1349 - accuracy: 0.9309\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1284 - accuracy: 0.9370\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1213 - accuracy: 0.9390\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1160 - accuracy: 0.9451\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1106 - accuracy: 0.9553\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1049 - accuracy: 0.9593\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1000 - accuracy: 0.9634\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0953 - accuracy: 0.9675\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0913 - accuracy: 0.9675\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0871 - accuracy: 0.9675\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0831 - accuracy: 0.9654\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0793 - accuracy: 0.9715\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0756 - accuracy: 0.9756\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0721 - accuracy: 0.9776\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0684 - accuracy: 0.9776\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0647 - accuracy: 0.9797\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0619 - accuracy: 0.9797\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0585 - accuracy: 0.9797\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0555 - accuracy: 0.9817\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0524 - accuracy: 0.9817\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0505 - accuracy: 0.9858\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0482 - accuracy: 0.9858\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0456 - accuracy: 0.9858\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0439 - accuracy: 0.9898\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0421 - accuracy: 0.9898\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0404 - accuracy: 0.9919\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0390 - accuracy: 0.9898\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0376 - accuracy: 0.9919\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0362 - accuracy: 0.9919\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0349 - accuracy: 0.9939\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0336 - accuracy: 0.9919\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0320 - accuracy: 0.9939\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 50us/sample - loss: 0.0316 - accuracy: 0.9959\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0302 - accuracy: 0.9939\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0291 - accuracy: 0.9939\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0283 - accuracy: 0.9939\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0272 - accuracy: 0.9939\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0265 - accuracy: 0.9959\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0257 - accuracy: 0.9939\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0253 - accuracy: 0.9939\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0244 - accuracy: 0.9939\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0238 - accuracy: 0.9959\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0226 - accuracy: 0.9959\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 46us/sample - loss: 0.0225 - accuracy: 0.9959\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0217 - accuracy: 0.9959\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0208 - accuracy: 0.9959\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0205 - accuracy: 0.9959\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 54us/sample - loss: 0.0200 - accuracy: 0.9959\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0191 - accuracy: 0.9959\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0188 - accuracy: 0.9959\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0190 - accuracy: 0.9959\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0178 - accuracy: 0.9959\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0175 - accuracy: 0.9959\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0169 - accuracy: 0.9980\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0169 - accuracy: 0.9980\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0165 - accuracy: 0.9980\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0167 - accuracy: 0.9980\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0156 - accuracy: 0.9980\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0152 - accuracy: 0.9980\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0156 - accuracy: 0.9980\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0151 - accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0144 - accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0143 - accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0137 - accuracy: 0.9980\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0134 - accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0131 - accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0130 - accuracy: 0.9980\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0126 - accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0124 - accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0121 - accuracy: 0.9980\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0121 - accuracy: 0.9980\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0116 - accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0114 - accuracy: 0.9980\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0112 - accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0110 - accuracy: 0.9980\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0109 - accuracy: 0.9980\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0111 - accuracy: 0.9980\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0106 - accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0104 - accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0102 - accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0106 - accuracy: 0.9980\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0097 - accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0099 - accuracy: 0.9980\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0094 - accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0091 - accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0094 - accuracy: 0.9980\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0091 - accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0090 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afb1ee5ec8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN2.fit(X_train, Y2_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.6883 - accuracy: 0.5671\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.5696 - accuracy: 0.9004\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.4571 - accuracy: 0.9472\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.3534 - accuracy: 0.9472\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 52us/sample - loss: 0.2720 - accuracy: 0.9472\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2183 - accuracy: 0.9472\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1864 - accuracy: 0.9472\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1687 - accuracy: 0.9472\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 62us/sample - loss: 0.1568 - accuracy: 0.9472\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1474 - accuracy: 0.9472\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1400 - accuracy: 0.9472\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1333 - accuracy: 0.9472\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1277 - accuracy: 0.9472\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1223 - accuracy: 0.9472\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.1179 - accuracy: 0.9472\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1126 - accuracy: 0.9472\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1081 - accuracy: 0.9472\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1035 - accuracy: 0.9472\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0995 - accuracy: 0.9472\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0956 - accuracy: 0.9472\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0917 - accuracy: 0.9472\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.0884 - accuracy: 0.9472\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0852 - accuracy: 0.9472\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0824 - accuracy: 0.9492\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0795 - accuracy: 0.9533\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0768 - accuracy: 0.9553\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0745 - accuracy: 0.9614\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0718 - accuracy: 0.9634\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0693 - accuracy: 0.9634\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0673 - accuracy: 0.9675\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0647 - accuracy: 0.9715\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0628 - accuracy: 0.9736\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0608 - accuracy: 0.9756\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0587 - accuracy: 0.9776\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0568 - accuracy: 0.9776\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0551 - accuracy: 0.9776\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0530 - accuracy: 0.9776\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.0516 - accuracy: 0.9797\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0497 - accuracy: 0.9837\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0481 - accuracy: 0.9817\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0465 - accuracy: 0.9858\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0455 - accuracy: 0.9837\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0445 - accuracy: 0.9858\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0427 - accuracy: 0.9878\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0416 - accuracy: 0.9878\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.0405 - accuracy: 0.9878\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0395 - accuracy: 0.9898\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0385 - accuracy: 0.9919\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 44us/sample - loss: 0.0374 - accuracy: 0.9898\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0367 - accuracy: 0.9898\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0357 - accuracy: 0.9878\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0347 - accuracy: 0.9898\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0338 - accuracy: 0.9919\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0333 - accuracy: 0.9939\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0323 - accuracy: 0.9919\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0316 - accuracy: 0.9939\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0306 - accuracy: 0.9939\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0302 - accuracy: 0.9939\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0296 - accuracy: 0.9939\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0288 - accuracy: 0.9939\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0283 - accuracy: 0.9939\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0275 - accuracy: 0.9939\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0270 - accuracy: 0.9939\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0264 - accuracy: 0.9939\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0258 - accuracy: 0.9959\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0253 - accuracy: 0.9959\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0247 - accuracy: 0.9959\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0247 - accuracy: 0.9959\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0241 - accuracy: 0.9959\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0235 - accuracy: 0.9959\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0233 - accuracy: 0.9959\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0226 - accuracy: 0.9959\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0228 - accuracy: 0.9959\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0221 - accuracy: 0.9959\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0223 - accuracy: 0.9959\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0213 - accuracy: 0.9959\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0215 - accuracy: 0.9959\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0217 - accuracy: 0.9939\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0213 - accuracy: 0.9959\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0199 - accuracy: 0.9959\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0197 - accuracy: 0.9959\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.0191 - accuracy: 0.9959\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0190 - accuracy: 0.9959\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0190 - accuracy: 0.9959\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0188 - accuracy: 0.9959\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0186 - accuracy: 0.9959\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0176 - accuracy: 0.9959\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0177 - accuracy: 0.9959\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0170 - accuracy: 0.9959\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0169 - accuracy: 0.9959\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0163 - accuracy: 0.9959\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0167 - accuracy: 0.9959\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0164 - accuracy: 0.9959\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0160 - accuracy: 0.9959\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0154 - accuracy: 0.9959\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0151 - accuracy: 0.9959\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0153 - accuracy: 0.9959\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0149 - accuracy: 0.9959\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0144 - accuracy: 0.9959\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0145 - accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afb22fc3c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN3.fit(X_train, Y3_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples\n",
      "Epoch 1/100\n",
      "492/492 [==============================] - 1s 1ms/sample - loss: 0.7255 - accuracy: 0.4553\n",
      "Epoch 2/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.5692 - accuracy: 0.8577\n",
      "Epoch 3/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.4532 - accuracy: 0.9329\n",
      "Epoch 4/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.3663 - accuracy: 0.9329\n",
      "Epoch 5/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.3015 - accuracy: 0.9329\n",
      "Epoch 6/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.2589 - accuracy: 0.9329\n",
      "Epoch 7/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.2338 - accuracy: 0.9329\n",
      "Epoch 8/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.2183 - accuracy: 0.9329\n",
      "Epoch 9/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.2094 - accuracy: 0.9329\n",
      "Epoch 10/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.2024 - accuracy: 0.9329\n",
      "Epoch 11/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1969 - accuracy: 0.9329\n",
      "Epoch 12/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1920 - accuracy: 0.9329\n",
      "Epoch 13/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1886 - accuracy: 0.9329\n",
      "Epoch 14/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1848 - accuracy: 0.9329\n",
      "Epoch 15/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.1812 - accuracy: 0.9329\n",
      "Epoch 16/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1773 - accuracy: 0.9329\n",
      "Epoch 17/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1740 - accuracy: 0.9329\n",
      "Epoch 18/100\n",
      "492/492 [==============================] - 0s 67us/sample - loss: 0.1709 - accuracy: 0.9329\n",
      "Epoch 19/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1673 - accuracy: 0.9329\n",
      "Epoch 20/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1643 - accuracy: 0.9329\n",
      "Epoch 21/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1614 - accuracy: 0.9329\n",
      "Epoch 22/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1588 - accuracy: 0.9329\n",
      "Epoch 23/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1558 - accuracy: 0.9329\n",
      "Epoch 24/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1532 - accuracy: 0.9329\n",
      "Epoch 25/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1505 - accuracy: 0.9329\n",
      "Epoch 26/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.1480 - accuracy: 0.9329\n",
      "Epoch 27/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1454 - accuracy: 0.9329\n",
      "Epoch 28/100\n",
      "492/492 [==============================] - 0s 63us/sample - loss: 0.1430 - accuracy: 0.9329\n",
      "Epoch 29/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1405 - accuracy: 0.9329\n",
      "Epoch 30/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1384 - accuracy: 0.9329\n",
      "Epoch 31/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1355 - accuracy: 0.9329\n",
      "Epoch 32/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1336 - accuracy: 0.9329\n",
      "Epoch 33/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1314 - accuracy: 0.9329\n",
      "Epoch 34/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1298 - accuracy: 0.9329\n",
      "Epoch 35/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.1270 - accuracy: 0.9329\n",
      "Epoch 36/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.1249 - accuracy: 0.9329\n",
      "Epoch 37/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1224 - accuracy: 0.9329\n",
      "Epoch 38/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.1203 - accuracy: 0.9329\n",
      "Epoch 39/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1181 - accuracy: 0.9350\n",
      "Epoch 40/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.1159 - accuracy: 0.9350\n",
      "Epoch 41/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.1141 - accuracy: 0.9350\n",
      "Epoch 42/100\n",
      "492/492 [==============================] - 0s 41us/sample - loss: 0.1120 - accuracy: 0.9370\n",
      "Epoch 43/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.1100 - accuracy: 0.9370\n",
      "Epoch 44/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1080 - accuracy: 0.9411\n",
      "Epoch 45/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.1058 - accuracy: 0.9472\n",
      "Epoch 46/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.1038 - accuracy: 0.9451\n",
      "Epoch 47/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.1018 - accuracy: 0.9512\n",
      "Epoch 48/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0996 - accuracy: 0.9512\n",
      "Epoch 49/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0984 - accuracy: 0.9512\n",
      "Epoch 50/100\n",
      "492/492 [==============================] - 0s 44us/sample - loss: 0.0957 - accuracy: 0.9512\n",
      "Epoch 51/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0939 - accuracy: 0.9512\n",
      "Epoch 52/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0917 - accuracy: 0.9512\n",
      "Epoch 53/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0897 - accuracy: 0.9512\n",
      "Epoch 54/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0879 - accuracy: 0.9512\n",
      "Epoch 55/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0862 - accuracy: 0.9512\n",
      "Epoch 56/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0846 - accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0822 - accuracy: 0.9553\n",
      "Epoch 58/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0812 - accuracy: 0.9553\n",
      "Epoch 59/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0793 - accuracy: 0.9553\n",
      "Epoch 60/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0775 - accuracy: 0.9573\n",
      "Epoch 61/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0759 - accuracy: 0.9593\n",
      "Epoch 62/100\n",
      "492/492 [==============================] - 0s 46us/sample - loss: 0.0749 - accuracy: 0.9634\n",
      "Epoch 63/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0725 - accuracy: 0.9654\n",
      "Epoch 64/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0712 - accuracy: 0.9654\n",
      "Epoch 65/100\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.0693 - accuracy: 0.9675\n",
      "Epoch 66/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0677 - accuracy: 0.9715\n",
      "Epoch 67/100\n",
      "492/492 [==============================] - 0s 61us/sample - loss: 0.0668 - accuracy: 0.9756\n",
      "Epoch 68/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0644 - accuracy: 0.9736\n",
      "Epoch 69/100\n",
      "492/492 [==============================] - 0s 48us/sample - loss: 0.0627 - accuracy: 0.9736\n",
      "Epoch 70/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0615 - accuracy: 0.9776\n",
      "Epoch 71/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0593 - accuracy: 0.9797\n",
      "Epoch 72/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0580 - accuracy: 0.9756\n",
      "Epoch 73/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0563 - accuracy: 0.9776\n",
      "Epoch 74/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0549 - accuracy: 0.9817\n",
      "Epoch 75/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0526 - accuracy: 0.9817\n",
      "Epoch 76/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0514 - accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0502 - accuracy: 0.9898\n",
      "Epoch 78/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0480 - accuracy: 0.9898\n",
      "Epoch 79/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0465 - accuracy: 0.9898\n",
      "Epoch 80/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0451 - accuracy: 0.9898\n",
      "Epoch 81/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0437 - accuracy: 0.9919\n",
      "Epoch 82/100\n",
      "492/492 [==============================] - 0s 53us/sample - loss: 0.0427 - accuracy: 0.9919\n",
      "Epoch 83/100\n",
      "492/492 [==============================] - 0s 49us/sample - loss: 0.0413 - accuracy: 0.9919\n",
      "Epoch 84/100\n",
      "492/492 [==============================] - 0s 43us/sample - loss: 0.0398 - accuracy: 0.9939\n",
      "Epoch 85/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0387 - accuracy: 0.9919\n",
      "Epoch 86/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0372 - accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0363 - accuracy: 0.9980\n",
      "Epoch 88/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0348 - accuracy: 0.9980\n",
      "Epoch 89/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0339 - accuracy: 0.9980\n",
      "Epoch 90/100\n",
      "492/492 [==============================] - 0s 47us/sample - loss: 0.0328 - accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0315 - accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0307 - accuracy: 0.9980\n",
      "Epoch 93/100\n",
      "492/492 [==============================] - 0s 45us/sample - loss: 0.0297 - accuracy: 0.9980\n",
      "Epoch 94/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0289 - accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "492/492 [==============================] - 0s 51us/sample - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 96/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0273 - accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0264 - accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 0.0255 - accuracy: 0.9980\n",
      "Epoch 99/100\n",
      "492/492 [==============================] - 0s 65us/sample - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.0242 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afb38d42c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN4.fit(X_train, Y4_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TarJ-uCY5DlX"
   },
   "source": [
    "Summary ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZcWucH15INv",
    "outputId": "7631fd1b-37f4-4d45-a3db-b53ed59e975b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  160       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ann0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              multiple                  160       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ann1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  160       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ann2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  160       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ann3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              multiple                  224       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ANN0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              multiple                  224       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ANN1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  224       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ANN2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              multiple                  224       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ANN3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              multiple                  224       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  17        \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ANN4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT  MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GOCCHAN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: modelaku\\assets\n"
     ]
    }
   ],
   "source": [
    "ann0.save(\"modelaku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ann0\\assets\n",
      "INFO:tensorflow:Assets written to: ann1\\assets\n",
      "INFO:tensorflow:Assets written to: ann2\\assets\n",
      "INFO:tensorflow:Assets written to: ann3\\assets\n"
     ]
    }
   ],
   "source": [
    "ann0.save(\"ann0\")\n",
    "ann1.save(\"ann1\")\n",
    "ann2.save(\"ann2\")\n",
    "ann3.save(\"ann3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ANN-0\\assets\n",
      "INFO:tensorflow:Assets written to: ANN-1\\assets\n",
      "INFO:tensorflow:Assets written to: ANN-2\\assets\n",
      "INFO:tensorflow:Assets written to: ANN-3\\assets\n",
      "INFO:tensorflow:Assets written to: ANN-4\\assets\n"
     ]
    }
   ],
   "source": [
    "ANN0.save(\"ANN-0\")\n",
    "ANN1.save(\"ANN-1\")\n",
    "ANN2.save(\"ANN-2\")\n",
    "ANN3.save(\"ANN-3\")\n",
    "ANN4.save(\"ANN-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOCCHAN\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['std_scaler.bin']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals.joblib import dump, load\n",
    "dump(sc, 'std_scaler.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['std_scaler2.bin']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(SC, 'std_scaler2.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = ann0_load.predict(sc.transform([[1,\n",
    "#                                         3,\n",
    "#                                         27,\n",
    "#                                         188]])) \n",
    "\n",
    "# print(pred)\n",
    "# if (pred > 0.5):\n",
    "#    print('ga ngapa2in 1')\n",
    "# else:\n",
    "#    print('ngapain 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIilHOXm5MIl"
   },
   "source": [
    "Testing ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Nilai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7n1HRB6XBASt",
    "outputId": "f6eaa4a3-ba1a-4efe-ece3-811c60294dcf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2840301]]\n",
      "ngapain 0\n"
     ]
    }
   ],
   "source": [
    "prediction0 = ann0.predict(sc.transform([[1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188]])) \n",
    "\n",
    "print(prediction0)\n",
    "if (prediction0 > 0.5):\n",
    "   print('ga ngapa2in 1')\n",
    "else:\n",
    "   print('ngapain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKFPKZSB_9Ah",
    "outputId": "cb3c6ccd-56b8-4a9f-c619-0be9f86b9917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.024081e-05]]\n",
      "ngapain lain 0\n"
     ]
    }
   ],
   "source": [
    "prediction1 = ann1.predict(sc.transform([[1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188]])) \n",
    "print(prediction1)\n",
    "if (prediction1 > 0.5):\n",
    "   print('ngapain lampu 1')\n",
    "else:\n",
    "   print('ngapain lain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00012494]]\n",
      "ngapain lain 0\n"
     ]
    }
   ],
   "source": [
    "prediction2 = ann2.predict(sc.transform([[1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188]])) \n",
    "\n",
    "print(prediction2)\n",
    "if (prediction2 > 0.5):\n",
    "   print('ngapain pompa 1')\n",
    "else:\n",
    "   print('ngapain lain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69821966]]\n",
      "ngapain pompa dan lampu 1\n"
     ]
    }
   ],
   "source": [
    "prediction3 = ann3.predict(sc.transform([[1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188]])) \n",
    "\n",
    "print(prediction3)\n",
    "if (prediction3 > 0.5):\n",
    "   print('ngapain pompa dan lampu 1')\n",
    "else:\n",
    "   print('ngapain lain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-edfcdcbcc9fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhasil_aktuator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasil_aktuator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction0' is not defined"
     ]
    }
   ],
   "source": [
    "a=[prediction0,prediction1,prediction2,prediction3]\n",
    "b=max(a);\n",
    "c=a.index(b)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00703871]]\n",
      "ngapain 0\n"
     ]
    }
   ],
   "source": [
    "Prediction0 = ANN0.predict(SC.transform([[6.5,\n",
    "                                        1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188,\n",
    "                                        622]])) \n",
    "\n",
    "print(Prediction0)\n",
    "if (Prediction0 > 0.5):\n",
    "   print('ga ngapa2in 1')\n",
    "else:\n",
    "   print('ngapain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03120493]]\n",
      "ngapain 0\n"
     ]
    }
   ],
   "source": [
    "Prediction1 = ANN1.predict(SC.transform([[6.5,\n",
    "                                        1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188,\n",
    "                                        622]])) \n",
    "\n",
    "print(Prediction1)\n",
    "if (Prediction1 > 0.5):\n",
    "   print('ngapain NOTIF 1 1')\n",
    "else:\n",
    "   print('ngapain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.758428e-13]]\n",
      "ngapain 0\n"
     ]
    }
   ],
   "source": [
    "Prediction2 = ANN2.predict(SC.transform([[6.5,\n",
    "                                        1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188,\n",
    "                                        622]])) \n",
    "\n",
    "print(Prediction2)\n",
    "if (Prediction2 > 0.5):\n",
    "   print('ngapain NOTIF 2 1')\n",
    "else:\n",
    "   print('ngapain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9059511]]\n",
      "ngapain NOTIF 3 1\n"
     ]
    }
   ],
   "source": [
    "Prediction3 = ANN3.predict(SC.transform([[6.5,\n",
    "                                        1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188,\n",
    "                                        622]])) \n",
    "\n",
    "print(Prediction3)\n",
    "if (Prediction3 > 0.5):\n",
    "   print('ngapain NOTIF 3 1')\n",
    "else:\n",
    "   print('ngapain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.716406e-06]]\n",
      "ngapain 0\n"
     ]
    }
   ],
   "source": [
    "Prediction4 = ANN4.predict(SC.transform([[6.5,\n",
    "                                        1,\n",
    "                                        3,\n",
    "                                        27,\n",
    "                                        188,\n",
    "                                        622]])) \n",
    "\n",
    "print(Prediction4)\n",
    "if (Prediction4 > 0.5):\n",
    "   print('ngapain NOTIF 4 1')\n",
    "else:\n",
    "   print('ngapain 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9059511]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "A=[Prediction0,Prediction1,Prediction2,Prediction3,Prediction4]\n",
    "B=max(A);\n",
    "C=A.index(B)\n",
    "print(B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "print (hasil_aktuator,hasil_notifikasi)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assembly ANN Solution",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
